#!/usr/bin/env python3
"""
AIè·¯ç”±å™¨æ¨¡å— - é€šè¿‡OpenRouterè°ƒç”¨å„ç§å¤§æ¨¡å‹
æ”¯æŒå¤šç§æ¨¡å‹çš„ç»Ÿä¸€æ¥å£å’Œæ™ºèƒ½è·¯ç”±
"""

from config import ConfigManager, AIClient
from typing import Dict, Any, List, Optional
import json
from datetime import datetime
from enum import Enum


class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾"""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    GOOGLE = "google"
    META = "meta-llama"
    MISTRAL = "mistralai"
    QWEN = "qwen"


class AIRouter:
    """AIè·¯ç”±å™¨ - é€šè¿‡OpenRouterç»Ÿä¸€è°ƒç”¨å¤šç§å¤§æ¨¡å‹"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config_manager = ConfigManager(config_path)
        self.ai_client = AIClient(self.config_manager)
        self.conversation_history = []
        self.current_model = self.config_manager.get_model()
    
    def switch_model(self, model_name: str) -> bool:
        """åˆ‡æ¢å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        self.current_model = model_name
        print(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {model_name}")
        return True
    
    def create_completion(self, 
                         messages: List[Dict[str, str]], 
                         model: Optional[str] = None,
                         **kwargs) -> str:
        """åˆ›å»ºèŠå¤©è¡¥å…¨"""
        try:
            model = model or self.current_model
            
            # è®¾ç½®é»˜è®¤å‚æ•°
            default_params = {
                # 'temperature': 0.7,
                # 'max_tokens': 2000,
                # 'top_p': 1.0,
                # 'frequency_penalty': 0.0,
                # 'presence_penalty': 0.0
            }
            
            # åˆå¹¶ç”¨æˆ·å‚æ•°
            params = {**default_params, **kwargs, 'model': model}
            
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
            
            return self.ai_client.create_chat_completion(messages, **params)
            
        except Exception as e:
            error_msg = str(e)
            if "401" in error_msg:
                raise Exception(f"APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸã€‚è¯·æ£€æŸ¥config.yamlä¸­çš„api_keyé…ç½®ã€‚\nè¯¦ç»†é”™è¯¯: {e}")
            elif "403" in error_msg:
                raise Exception(f"APIè®¿é—®è¢«æ‹’ç»ã€‚è¯·æ£€æŸ¥APIå¯†é’¥æƒé™ã€‚\nè¯¦ç»†é”™è¯¯: {e}")
            elif "404" in error_msg:
                raise Exception(f"æ¨¡å‹ '{model}' ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨ã€‚\nè¯¦ç»†é”™è¯¯: {e}")
            elif "429" in error_msg:
                raise Exception(f"APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚\nè¯¦ç»†é”™è¯¯: {e}")
            else:
                raise Exception(f"AIè¯·æ±‚å¤±è´¥: {e}")
    
    def test_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            test_messages = [{"role": "user", "content": "Hello"}]
            response = self.create_completion(test_messages)
            print(f"âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def chat(self, 
             user_message: str, 
             system_prompt: Optional[str] = None,
             model: Optional[str] = None,
             use_history: bool = True) -> str:
        """ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯"""
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤º
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_history:
            messages.extend(self.conversation_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user", 
            "content": user_message
        })
        
        # è·å–AIå“åº”
        response = self.create_completion(messages, model)
        
        # æ›´æ–°å¯¹è¯å†å²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_history:
            self.conversation_history.append({"role": "user", "content": user_message})
            self.conversation_history.append({"role": "assistant", "content": response})
        
        return response
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
    
    def get_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.copy()
    
    def save_conversation(self, filename: str = None):
        """ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.json"
        
        conversation_data = {
            "timestamp": datetime.now().isoformat(),
            "model": self.current_model,
            "conversation": self.conversation_history
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜åˆ°: {filename}")
    
    def load_conversation(self, filename: str):
        """ä»æ–‡ä»¶åŠ è½½å¯¹è¯"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                conversation_data = json.load(f)
            
            self.conversation_history = conversation_data.get("conversation", [])
            if "model" in conversation_data:
                self.current_model = conversation_data["model"]
            
            print(f"ğŸ“‚ å·²åŠ è½½å¯¹è¯: {filename}")
            print(f"ğŸ¤– æ¨¡å‹: {self.current_model}")
            print(f"ğŸ’¬ æ¶ˆæ¯æ•°: {len(self.conversation_history)}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹è¯å¤±è´¥: {e}")


class InteractiveChat:
    """äº¤äº’å¼èŠå¤©ç•Œé¢"""
    
    def __init__(self, ai_router: AIRouter):
        self.ai_router = ai_router
        self.session_start_time = datetime.now()
    
    def start(self):
        """å¯åŠ¨äº¤äº’å¼èŠå¤©"""
        print("=" * 70)
        print("ğŸ¤– AIåŠ©æ‰‹ - é€šè¿‡OpenRouterè¿æ¥å¤šç§å¤§æ¨¡å‹")
        print("=" * 70)
        print(f"å½“å‰æ¨¡å‹: {self.ai_router.current_model}")
        print("\nğŸ“ å¯ç”¨å‘½ä»¤:")
        print("  'quit' æˆ– 'exit' - é€€å‡º")
        print("  'clear' - æ¸…ç©ºå¯¹è¯å†å²")
        print("  'models' - æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        print("  'switch <æ¨¡å‹å>' - åˆ‡æ¢æ¨¡å‹")
        print("  'save [æ–‡ä»¶å]' - ä¿å­˜å¯¹è¯")
        print("  'load <æ–‡ä»¶å>' - åŠ è½½å¯¹è¯")
        print("  'history' - æŸ¥çœ‹å¯¹è¯å†å²")
        print("-" * 70)
        
        # é»˜è®¤ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½ã€æœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ï¼Œå¹¶å°½é‡æä¾›è¯¦ç»†å’Œå‡†ç¡®çš„ä¿¡æ¯ã€‚
å¯¹äºä»£ç ç›¸å…³çš„é—®é¢˜ï¼Œè¯·æä¾›æ¸…æ™°çš„è§£é‡Šå’Œç¤ºä¾‹ã€‚"""
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ ä½ : ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                elif user_input.lower() == 'clear':
                    self.ai_router.clear_history()
                    continue
                elif user_input.lower() == 'models':
                    self._show_models()
                    continue
                elif user_input.lower().startswith('switch '):
                    model_name = user_input[7:].strip()
                    self.ai_router.switch_model(model_name)
                    continue
                elif user_input.lower().startswith('save'):
                    parts = user_input.split(' ', 1)
                    filename = parts[1] if len(parts) > 1 else None
                    self.ai_router.save_conversation(filename)
                    continue
                elif user_input.lower().startswith('load '):
                    filename = user_input[5:].strip()
                    self.ai_router.load_conversation(filename)
                    continue
                elif user_input.lower() == 'history':
                    self._show_history()
                    continue
                
                print("\nğŸ¤– AIåŠ©æ‰‹æ­£åœ¨æ€è€ƒ...")
                
                # è·å–AIå“åº”
                response = self.ai_router.chat(user_input, system_prompt)
                
                print(f"\nğŸ¤– AIåŠ©æ‰‹: {response}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
    
    def _show_models(self):
        """æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯"""
        print(f"\nğŸ“‹ å½“å‰ä½¿ç”¨çš„æ¨¡å‹: {self.ai_router.current_model}")
        print("\nï¿½ æç¤º: ä½ å¯ä»¥ä½¿ç”¨ 'switch <æ¨¡å‹å>' åˆ‡æ¢åˆ°ä»»ä½•OpenRouteræ”¯æŒçš„æ¨¡å‹")
        print("   å¸¸ç”¨æ¨¡å‹ç¤ºä¾‹:")
        print("   - openai/gpt-4o")
        print("   - anthropic/claude-3-sonnet")
        print("   - meta-llama/llama-3-70b-instruct")
        print("   - mistralai/mixtral-8x7b-instruct")
        print("ä½¿ç”¨ 'switch <æ¨¡å‹å>' åˆ‡æ¢æ¨¡å‹")
    
    def _show_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        history = self.ai_router.get_history()
        
        if not history:
            print("ğŸ“­ æš‚æ— å¯¹è¯å†å²")
            return
        
        print(f"\nğŸ“š å¯¹è¯å†å² ({len(history)} æ¡æ¶ˆæ¯):")
        print("-" * 50)
        
        for i, msg in enumerate(history, 1):
            role_icon = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
            role_name = "ä½ " if msg["role"] == "user" else "AIåŠ©æ‰‹"
            content = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
            print(f"{i:2d}. {role_icon} {role_name}: {content}")
        
        print("-" * 50)


def demo_code_review():
    """æ¼”ç¤ºä»£ç å®¡æŸ¥åŠŸèƒ½"""
    try:
        ai_router = AIRouter()
        
        print("ğŸ” ä»£ç å®¡æŸ¥æ¼”ç¤º")
        print("-" * 40)
        
        code_sample = '''
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# ä½¿ç”¨ç¤ºä¾‹
for i in range(10):
    print(f"fibonacci({i}) = {fibonacci(i)}")
        '''
        
        review_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä»£ç å¹¶æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ï¼ŒåŒ…æ‹¬ï¼š
1. ä»£ç è´¨é‡è¯„ä¼°
2. æ€§èƒ½é—®é¢˜åˆ†æ
3. æ½œåœ¨çš„bugæˆ–é—®é¢˜
4. æ”¹è¿›å»ºè®®å’Œæœ€ä½³å®è·µ
5. é‡æ„å»ºè®®ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        
        question = f"è¯·å®¡æŸ¥ä»¥ä¸‹Pythonä»£ç ï¼š\n```python{code_sample}\n```"
        
        response = ai_router.chat(question, review_prompt, use_history=False)
        print(f"\nğŸ¤– ä»£ç å®¡æŸ¥ç»“æœ:\n{response}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


def demo_model_comparison():
    """æ¼”ç¤ºä¸åŒæ¨¡å‹çš„å¯¹æ¯”"""
    try:
        ai_router = AIRouter()
        
        print("âš–ï¸  æ¨¡å‹å¯¹æ¯”æ¼”ç¤º")
        print("-" * 40)
        
        question = "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚"
        models_to_test = ["openai/gpt-4o", "anthropic/claude-3-sonnet", "meta-llama/llama-3-70b-instruct"]
        
        for model in models_to_test:
            try:
                print(f"\nğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
                print("-" * 30)
                response = ai_router.chat(question, model=model, use_history=False)
                print(f"å›ç­”: {response[:200]}...")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ {model} è°ƒç”¨å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æ¼”ç¤ºå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        print("ğŸš€ AIè·¯ç”±å™¨ - å¤šæ¨¡å‹å¯¹è¯å¹³å°")
        print("=" * 50)
        
        # åˆå§‹åŒ–AIè·¯ç”±å™¨
        ai_router = AIRouter()
        
        # é¦–å…ˆæµ‹è¯•APIè¿æ¥
        print("ï¿½ æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
        if not ai_router.test_connection():
            print("\nâŒ APIè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®:")
            print("1. config.yaml æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
            print("2. APIå¯†é’¥æ˜¯å¦æ­£ç¡®ä¸”æœ‰æ•ˆ")
            print("3. base_url æ˜¯å¦æ­£ç¡®")
            print("4. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            return
        
        print("\né€‰æ‹©åŠŸèƒ½:")
        print("1. äº¤äº’å¼èŠå¤©")
        print("2. ä»£ç å®¡æŸ¥æ¼”ç¤º")
        print("3. æ¨¡å‹å¯¹æ¯”æ¼”ç¤º")
        print("4. å•æ¬¡é—®ç­”")
        print("5. é€€å‡º")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
            
            if choice == '1':
                chat = InteractiveChat(ai_router)
                chat.start()
                break
            elif choice == '2':
                demo_code_review()
                break
            elif choice == '3':
                demo_model_comparison()
                break
            elif choice == '4':
                question = input("è¯·è¾“å…¥ä½ çš„é—®é¢˜: ")
                response = ai_router.chat(question, use_history=False)
                print(f"\nğŸ¤– AIå›ç­”: {response}")
                break
            elif choice == '5':
                print("ğŸ‘‹ å†è§ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ æç¤º:")
        print("1. è¯·ç¡®ä¿ config.yaml æ–‡ä»¶å­˜åœ¨ä¸”é…ç½®æ­£ç¡®")
        print("2. è¯·æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("3. è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")


if __name__ == "__main__":
    main()