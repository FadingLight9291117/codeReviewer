import subprocess
import os
import re
from typing import List, Dict, Set, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import json


@dataclass
class GitCommit:
    """Gitæäº¤ä¿¡æ¯æ•°æ®ç±»"""
    hash: str
    author: str
    email: str
    date: datetime
    message: str
    files_changed: List[str]
    additions: int
    deletions: int


@dataclass
class GitFileChange:
    """Gitæ–‡ä»¶å˜æ›´ä¿¡æ¯"""
    file_path: str
    change_type: str  # A(æ–°å¢), M(ä¿®æ”¹), D(åˆ é™¤), R(é‡å‘½å)
    additions: int
    deletions: int
    old_path: Optional[str] = None  # é‡å‘½åæ—¶çš„åŸè·¯å¾„


class GitAnalyzer:
    """Gitä»“åº“åˆ†æå™¨"""
    
    def __init__(self, repo_path: str):
        """
        åˆå§‹åŒ–Gitåˆ†æå™¨
        
        Args:
            repo_path: Gitä»“åº“æ ¹ç›®å½•è·¯å¾„
        """
        self.repo_path = os.path.abspath(repo_path)
        self._validate_git_repo()
    
    def _validate_git_repo(self):
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Gitä»“åº“"""
        git_dir = os.path.join(self.repo_path, '.git')
        if not os.path.exists(git_dir):
            raise ValueError(f"'{self.repo_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„Gitä»“åº“")
    
    def _run_git_command(self, command: List[str]) -> str:
        """
        æ‰§è¡ŒGitå‘½ä»¤
        
        Args:
            command: Gitå‘½ä»¤åˆ—è¡¨
            
        Returns:
            å‘½ä»¤è¾“å‡ºç»“æœ
        """
        try:
            result = subprocess.run(
                ['git'] + command,
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                encoding='utf-8',
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e.stderr}")
        except UnicodeDecodeError:
            # å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜
            result = subprocess.run(
                ['git'] + command,
                cwd=self.repo_path,
                capture_output=True,
                check=True
            )
            return result.stdout.decode('utf-8', errors='ignore').strip()
    
    def get_commits_by_prefix(self, prefix: str, 
                            since: Optional[str] = None,
                            until: Optional[str] = None,
                            max_count: Optional[int] = None) -> List[GitCommit]:
        """
        æ ¹æ®æäº¤æ¶ˆæ¯å‰ç¼€æŸ¥æ‰¾æäº¤è®°å½•
        
        Args:
            prefix: æäº¤æ¶ˆæ¯å‰ç¼€ (å¦‚: 'feat:', 'fix:', 'JIRA-123:')
            since: å¼€å§‹æ—¶é—´ (å¦‚: '2023-01-01', '1 week ago')
            until: ç»“æŸæ—¶é—´
            max_count: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            åŒ¹é…çš„æäº¤è®°å½•åˆ—è¡¨
        """
        command = ['log', '--oneline', '--pretty=format:%H|%an|%ae|%ad|%s', 
                  '--date=iso']
        
        if since:
            command.extend(['--since', since])
        if until:
            command.extend(['--until', until])
        if max_count:
            command.extend(['-n', str(max_count)])
        
        output = self._run_git_command(command)
        if not output:
            return []
        
        commits = []
        # æ ‡å‡†åŒ–å‰ç¼€ï¼šç§»é™¤ç»“å°¾çš„å†’å·å’Œç©ºæ ¼ï¼Œè½¬ä¸ºå°å†™æ¯”è¾ƒ
        normalized_prefix = prefix.rstrip(': ').lower()
        
        for line in output.split('\n'):
            if not line.strip():
                continue
                
            parts = line.split('|', 4)
            if len(parts) != 5:
                continue
                
            commit_hash, author, email, date_str, message = parts
            
            # ç®€åŒ–å‰ç¼€åŒ¹é…é€»è¾‘ï¼šæ£€æŸ¥æäº¤æ¶ˆæ¯æ˜¯å¦åŒ…å«æŒ‡å®šå‰ç¼€
            normalized_message = message.lower().strip()
            
            # æ–¹æ³•1ï¼šç›´æ¥å‰ç¼€åŒ¹é…
            prefix_matches = normalized_message.startswith(normalized_prefix)
            
            # æ–¹æ³•2ï¼šå¦‚æœå‰ç¼€åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä¹Ÿå°è¯•éƒ¨åˆ†åŒ¹é…
            if not prefix_matches and len(normalized_prefix) > 10:
                # å¯¹äºé•¿å‰ç¼€ï¼Œå°è¯•åŒ¹é…å‰é¢çš„å…³é”®éƒ¨åˆ†
                key_parts = normalized_prefix.split()[:2]  # å–å‰ä¸¤ä¸ªè¯
                if len(key_parts) >= 2:
                    key_prefix = ' '.join(key_parts)
                    prefix_matches = normalized_message.startswith(key_prefix)
            
            if prefix_matches:
                
                try:
                    commit_date = datetime.fromisoformat(date_str.replace(' ', 'T', 1))
                except ValueError:
                    # å¤„ç†æ—¥æœŸè§£æå¤±è´¥
                    commit_date = datetime.now()
                
                # è·å–è¯¦ç»†çš„æäº¤ä¿¡æ¯
                detailed_commit = self._get_commit_details(commit_hash)
                commits.append(detailed_commit)
        
        return commits
        
    def get_commits_by_multiple_prefixes_fast(self, prefixes: List[str], 
                                            since: Optional[str] = None,
                                            until: Optional[str] = None,
                                            max_count: Optional[int] = None) -> Dict[str, List[GitCommit]]:
        """
        æ ¹æ®å¤šä¸ªæäº¤æ¶ˆæ¯å‰ç¼€æŸ¥æ‰¾æäº¤è®°å½• (æé€Ÿä¼˜åŒ–ç‰ˆæœ¬)
        æ‰¹é‡è·å–æäº¤è¯¦æƒ…ï¼Œå¤§å¹…æå‡æ€§èƒ½
        
        Args:
            prefixes: æäº¤æ¶ˆæ¯å‰ç¼€åˆ—è¡¨
            since: å¼€å§‹æ—¶é—´
            until: ç»“æŸæ—¶é—´
            max_count: æ¯ä¸ªå‰ç¼€çš„æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            å‰ç¼€åˆ°æäº¤è®°å½•åˆ—è¡¨çš„æ˜ å°„
        """
        if not prefixes:
            return {}
        
        # ç¬¬ä¸€æ­¥ï¼šè·å–æ‰€æœ‰æäº¤çš„åŸºæœ¬ä¿¡æ¯
        command = ['log', '--oneline', '--pretty=format:%H|%an|%ae|%ad|%s', 
                  '--date=iso']
        
        if since:
            command.extend(['--since', since])
        if until:
            command.extend(['--until', until])
        
        output = self._run_git_command(command)
        if not output:
            return {}
        
        # æ ‡å‡†åŒ–æ‰€æœ‰å‰ç¼€
        normalized_prefixes = {prefix.rstrip(': ').lower(): prefix for prefix in prefixes}
        matching_commits = {}  # hash -> (prefix_list, basic_info)
        
        # ç¬¬äºŒæ­¥ï¼šåœ¨å†…å­˜ä¸­è¿›è¡Œå‰ç¼€åŒ¹é…ï¼Œæ”¶é›†æ‰€æœ‰åŒ¹é…çš„æäº¤å“ˆå¸Œ
        for line in output.split('\n'):
            if not line.strip():
                continue
                
            parts = line.split('|', 4)
            if len(parts) != 5:
                continue
                
            commit_hash, author, email, date_str, message = parts
            normalized_message = message.lower().strip()
            
            matched_prefixes = []
            for norm_prefix, original_prefix in normalized_prefixes.items():
                prefix_matches = normalized_message.startswith(norm_prefix)
                
                if not prefix_matches and len(norm_prefix) > 10:
                    key_parts = norm_prefix.split()[:2]
                    if len(key_parts) >= 2:
                        key_prefix = ' '.join(key_parts)
                        prefix_matches = normalized_message.startswith(key_prefix)
                
                if prefix_matches:
                    matched_prefixes.append(original_prefix)
            
            if matched_prefixes:
                matching_commits[commit_hash] = (matched_prefixes, parts)
        
        if not matching_commits:
            return {prefix: [] for prefix in prefixes}
        
        # ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡è·å–æ‰€æœ‰åŒ¹é…æäº¤çš„è¯¦ç»†ä¿¡æ¯
        commit_hashes = list(matching_commits.keys())
        
        # æ‰¹é‡è·å–æ–‡ä»¶å˜æ›´ä¿¡æ¯
        files_info = self._get_commits_files_batch(commit_hashes)
        
        # æ‰¹é‡è·å–ç»Ÿè®¡ä¿¡æ¯
        stats_info = self._get_commits_stats_batch(commit_hashes)
        
        # ç¬¬å››æ­¥ï¼šæ„å»ºç»“æœ
        results = {prefix: [] for prefix in prefixes}
        
        for commit_hash, (matched_prefixes, basic_parts) in matching_commits.items():
            commit_hash, author, email, date_str, message = basic_parts
            
            try:
                commit_date = datetime.fromisoformat(date_str.replace(' ', 'T', 1))
            except ValueError:
                commit_date = datetime.now()
            
            files_changed = files_info.get(commit_hash, [])
            additions, deletions = stats_info.get(commit_hash, (0, 0))
            
            commit_obj = GitCommit(
                hash=commit_hash,
                author=author,
                email=email,
                date=commit_date,
                message=message,
                files_changed=files_changed,
                additions=additions,
                deletions=deletions
            )
            
            # å°†æäº¤æ·»åŠ åˆ°æ‰€æœ‰åŒ¹é…çš„å‰ç¼€ä¸­
            for prefix in matched_prefixes:
                results[prefix].append(commit_obj)
                
                # åº”ç”¨æœ€å¤§æ•°é‡é™åˆ¶
                if max_count and len(results[prefix]) >= max_count:
                    break
        
        # è¿‡æ»¤ç©ºç»“æœ
        return {prefix: commits for prefix, commits in results.items() if commits}
    
    def _get_commits_files_batch(self, commit_hashes: List[str]) -> Dict[str, List[str]]:
        """æ‰¹é‡è·å–å¤šä¸ªæäº¤çš„æ–‡ä»¶å˜æ›´ä¿¡æ¯"""
        if not commit_hashes:
            return {}
        
        files_info = {}
        
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å‘½ä»¤è¡Œè¿‡é•¿
        batch_size = 50
        for i in range(0, len(commit_hashes), batch_size):
            batch_hashes = commit_hashes[i:i + batch_size]
            
            try:
                # ä½¿ç”¨ git show --name-only æ‰¹é‡è·å–æ–‡ä»¶ä¿¡æ¯
                for commit_hash in batch_hashes:
                    output = self._run_git_command([
                        'show', '--name-only', '--format=', commit_hash
                    ])
                    files_changed = [line.strip() for line in output.split('\n') if line.strip()]
                    files_info[commit_hash] = files_changed
                    
            except Exception as e:
                print(f"è­¦å‘Š: æ‰¹é‡è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
                # é™çº§åˆ°å•ä¸ªå¤„ç†
                for commit_hash in batch_hashes:
                    try:
                        output = self._run_git_command([
                            'show', '--name-only', '--format=', commit_hash
                        ])
                        files_changed = [line.strip() for line in output.split('\n') if line.strip()]
                        files_info[commit_hash] = files_changed
                    except:
                        files_info[commit_hash] = []
        
        return files_info
    
    def _get_commits_stats_batch(self, commit_hashes: List[str]) -> Dict[str, Tuple[int, int]]:
        """æ‰¹é‡è·å–å¤šä¸ªæäº¤çš„ç»Ÿè®¡ä¿¡æ¯"""
        if not commit_hashes:
            return {}
        
        stats_info = {}
        
        # åˆ†æ‰¹å¤„ç†
        batch_size = 50
        for i in range(0, len(commit_hashes), batch_size):
            batch_hashes = commit_hashes[i:i + batch_size]
            
            try:
                for commit_hash in batch_hashes:
                    output = self._run_git_command([
                        'show', '--stat', '--format=', commit_hash
                    ])
                    additions, deletions = self._parse_stats(output)
                    stats_info[commit_hash] = (additions, deletions)
                    
            except Exception as e:
                print(f"è­¦å‘Š: æ‰¹é‡è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                # é™çº§åˆ°å•ä¸ªå¤„ç†
                for commit_hash in batch_hashes:
                    try:
                        output = self._run_git_command([
                            'show', '--stat', '--format=', commit_hash
                        ])
                        additions, deletions = self._parse_stats(output)
                        stats_info[commit_hash] = (additions, deletions)
                    except:
                        stats_info[commit_hash] = (0, 0)
        
        return stats_info
    
    def get_files_by_commit_prefix(self, prefix: str, 
                                 include_dependencies: bool = True,
                                 since: Optional[str] = None) -> Dict[str, Any]:
        """
        æ ¹æ®æäº¤å‰ç¼€è·å–ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶
        
        Args:
            prefix: æäº¤æ¶ˆæ¯å‰ç¼€
            include_dependencies: æ˜¯å¦åŒ…å«ä¾èµ–æ–‡ä»¶
            since: æ—¶é—´èŒƒå›´é™åˆ¶
            
        Returns:
            åŒ…å«ç›¸å…³æ–‡ä»¶å’Œåˆ†æç»“æœçš„å­—å…¸
        """
        # 1. æŸ¥æ‰¾ç›¸å…³æäº¤
        commits = self.get_commits_by_prefix(prefix, since=since)
        
        if not commits:
            return {
                'prefix': prefix,
                'commits': [],
                'direct_files': set(),
                'related_files': set(),
                'file_changes': {},
                'summary': {
                    'total_commits': 0,
                    'total_files': 0,
                    'total_additions': 0,
                    'total_deletions': 0
                }
            }
        
        # 2. è·å–ç›´æ¥ä¿®æ”¹çš„æ–‡ä»¶
        direct_files = set()
        total_additions = total_deletions = 0
        
        for commit in commits:
            direct_files.update(commit.files_changed)
            total_additions += commit.additions
            total_deletions += commit.deletions
        
        # 3. è·å–æ–‡ä»¶å˜æ›´è¯¦æƒ…
        file_changes = self.get_file_changes_by_commits(commits)
        
        # 4. æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶ (å¦‚æœå¯ç”¨ä¾èµ–åˆ†æ)
        related_files = set(direct_files)
        if include_dependencies:
            related_files.update(self._find_dependency_files(direct_files))
        
        return {
            'prefix': prefix,
            'commits': commits,
            'direct_files': direct_files,
            'related_files': related_files,
            'file_changes': file_changes,
            'summary': {
                'total_commits': len(commits),
                'total_files': len(related_files),
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'time_range': {
                    'start': min(c.date for c in commits) if commits else None,
                    'end': max(c.date for c in commits) if commits else None
                }
            }
        }
    
    def _get_commit_details(self, commit_hash: str) -> GitCommit:
        """
        è·å–æäº¤çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            commit_hash: æäº¤å“ˆå¸Œå€¼
            
        Returns:
            è¯¦ç»†çš„æäº¤ä¿¡æ¯
        """
        # è·å–åŸºæœ¬ä¿¡æ¯
        basic_info = self._run_git_command([
            'show', '--pretty=format:%H|%an|%ae|%ad|%s', '--date=iso', 
            '--name-only', commit_hash
        ])
        
        lines = basic_info.split('\n')
        header = lines[0].split('|', 4)
        
        commit_hash, author, email, date_str, message = header
        commit_date = datetime.fromisoformat(date_str.replace(' ', 'T', 1))
        
        # è·å–å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨ - ä¿®å¤ï¼šåº”è¯¥ä»ç¬¬1è¡Œå¼€å§‹ï¼Œè€Œä¸æ˜¯ç¬¬2è¡Œ
        files_changed = [line.strip() for line in lines[1:] if line.strip()]
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self._run_git_command(['show', '--stat', '--format=', commit_hash])
        additions, deletions = self._parse_stats(stats)
        
        return GitCommit(
            hash=commit_hash,
            author=author,
            email=email,
            date=commit_date,
            message=message,
            files_changed=files_changed,
            additions=additions,
            deletions=deletions
        )
    
    def _parse_stats(self, stats_output: str) -> Tuple[int, int]:
        """è§£æGitç»Ÿè®¡ä¿¡æ¯"""
        additions = deletions = 0
        
        # æŸ¥æ‰¾ç»Ÿè®¡è¡Œï¼Œæ ¼å¼å¦‚: "2 files changed, 10 insertions(+), 5 deletions(-)"
        pattern = r'(\d+)\s+insertion.*?(\d+)\s+deletion'
        match = re.search(pattern, stats_output)
        
        if match:
            additions = int(match.group(1))
            deletions = int(match.group(2))
        else:
            # å•ç‹¬æŸ¥æ‰¾æ’å…¥å’Œåˆ é™¤
            insert_match = re.search(r'(\d+)\s+insertion', stats_output)
            delete_match = re.search(r'(\d+)\s+deletion', stats_output)
            
            if insert_match:
                additions = int(insert_match.group(1))
            if delete_match:
                deletions = int(delete_match.group(1))
        
        return additions, deletions
    
    def get_file_changes_by_commits(self, commits: List[GitCommit]) -> Dict[str, List[GitFileChange]]:
        """
        è·å–æäº¤ä¸­çš„æ–‡ä»¶å˜æ›´è¯¦æƒ…
        
        Args:
            commits: æäº¤è®°å½•åˆ—è¡¨
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ°å˜æ›´ä¿¡æ¯çš„æ˜ å°„
        """
        file_changes = {}
        
        for commit in commits:
            commit_changes = self._get_commit_file_changes(commit.hash)
            
            for change in commit_changes:
                if change.file_path not in file_changes:
                    file_changes[change.file_path] = []
                file_changes[change.file_path].append(change)
        
        return file_changes
    
    def _get_commit_file_changes(self, commit_hash: str) -> List[GitFileChange]:
        """è·å–å•ä¸ªæäº¤çš„æ–‡ä»¶å˜æ›´"""
        try:
            # ä½¿ç”¨ --numstat è·å–è¯¦ç»†çš„å˜æ›´ç»Ÿè®¡
            output = self._run_git_command([
                'show', '--numstat', '--name-status', '--format=', commit_hash
            ])
            
            changes = []
            lines = [line.strip() for line in output.split('\n') if line.strip()]
            
            # è§£ænumstatè¾“å‡º (æ ¼å¼: additions deletions filename)
            numstat_lines = []
            namestatus_lines = []
            
            for line in lines:
                if '\t' in line and line.split('\t')[0].isdigit():
                    numstat_lines.append(line)
                elif line[0] in 'AMDRC':
                    namestatus_lines.append(line)
            
            # åˆå¹¶numstatå’Œname-statusä¿¡æ¯
            for i, numstat_line in enumerate(numstat_lines):
                parts = numstat_line.split('\t')
                if len(parts) >= 3:
                    additions = int(parts[0]) if parts[0] != '-' else 0
                    deletions = int(parts[1]) if parts[1] != '-' else 0
                    file_path = parts[2]
                    
                    # æŸ¥æ‰¾å¯¹åº”çš„çŠ¶æ€ä¿¡æ¯
                    change_type = 'M'  # é»˜è®¤ä¸ºä¿®æ”¹
                    old_path = None
                    
                    if i < len(namestatus_lines):
                        status_line = namestatus_lines[i]
                        change_type = status_line[0]
                        
                        if change_type == 'R':  # é‡å‘½å
                            status_parts = status_line.split('\t')
                            if len(status_parts) >= 3:
                                old_path = status_parts[1]
                                file_path = status_parts[2]
                    
                    changes.append(GitFileChange(
                        file_path=file_path,
                        change_type=change_type,
                        additions=additions,
                        deletions=deletions,
                        old_path=old_path
                    ))
            
            return changes
            
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è·å–æäº¤ {commit_hash} çš„æ–‡ä»¶å˜æ›´: {e}")
            return []
    
    def get_related_files_by_requirement(self, requirement_pattern: str,
                                       include_dependencies: bool = True,
                                       since: Optional[str] = None) -> Dict[str, Any]:
        """
        æ ¹æ®éœ€æ±‚æ¨¡å¼è·å–ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶
        
        Args:
            requirement_pattern: éœ€æ±‚ç›¸å…³çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            include_dependencies: æ˜¯å¦åŒ…å«ä¾èµ–æ–‡ä»¶
            since: æ—¶é—´èŒƒå›´é™åˆ¶
            
        Returns:
            åŒ…å«ç›¸å…³æ–‡ä»¶å’Œåˆ†æç»“æœçš„å­—å…¸
        """
        # 1. æŸ¥æ‰¾ç›¸å…³æäº¤
        commits = self.get_commits_by_message_pattern(
            requirement_pattern, since=since
        )
        
        if not commits:
            return {
                'commits': [],
                'direct_files': set(),
                'related_files': set(),
                'file_changes': {},
                'summary': {
                    'total_commits': 0,
                    'total_files': 0,
                    'total_additions': 0,
                    'total_deletions': 0
                }
            }
        
        # 2. è·å–ç›´æ¥ä¿®æ”¹çš„æ–‡ä»¶
        direct_files = set()
        total_additions = total_deletions = 0
        
        for commit in commits:
            direct_files.update(commit.files_changed)
            total_additions += commit.additions
            total_deletions += commit.deletions
        
        # 3. è·å–æ–‡ä»¶å˜æ›´è¯¦æƒ…
        file_changes = self.get_file_changes_by_commits(commits)
        
        # 4. æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶ (å¦‚æœå¯ç”¨ä¾èµ–åˆ†æ)
        related_files = set(direct_files)
        if include_dependencies:
            related_files.update(self._find_dependency_files(direct_files))
        
        return {
            'commits': commits,
            'direct_files': direct_files,
            'related_files': related_files,
            'file_changes': file_changes,
            'summary': {
                'total_commits': len(commits),
                'total_files': len(related_files),
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'time_range': {
                    'start': min(c.date for c in commits) if commits else None,
                    'end': max(c.date for c in commits) if commits else None
                }
            }
        }
    
    def get_related_files_by_requirement(self, requirement_pattern: str,
                                       include_dependencies: bool = True,
                                       since: Optional[str] = None) -> Dict[str, Any]:
        """
        æ ¹æ®éœ€æ±‚æ¨¡å¼è·å–ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶ (ä¿ç•™å‘åå…¼å®¹æ€§)
        
        Args:
            requirement_pattern: éœ€æ±‚ç›¸å…³çš„æ¨¡å¼ (å¯ä»¥æ˜¯å‰ç¼€æˆ–æ­£åˆ™è¡¨è¾¾å¼)
            include_dependencies: æ˜¯å¦åŒ…å«ä¾èµ–æ–‡ä»¶
            since: æ—¶é—´èŒƒå›´é™åˆ¶
            
        Returns:
            åŒ…å«ç›¸å…³æ–‡ä»¶å’Œåˆ†æç»“æœçš„å­—å…¸
        """
        # å¦‚æœæ¨¡å¼çœ‹èµ·æ¥åƒå‰ç¼€ï¼Œä½¿ç”¨å‰ç¼€åŒ¹é…
        if ':' in requirement_pattern or requirement_pattern.endswith((' ', '-')):
            return self.get_files_by_commit_prefix(
                requirement_pattern, include_dependencies, since
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰çš„æ¨¡å¼åŒ¹é…é€»è¾‘
        return self._get_files_by_pattern_matching(
            requirement_pattern, include_dependencies, since
        )
    
    def _get_files_by_pattern_matching(self, pattern: str,
                                     include_dependencies: bool = True,
                                     since: Optional[str] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼åŒ¹é…è·å–æ–‡ä»¶ (åŸæœ‰é€»è¾‘)
        """
        command = ['log', '--oneline', '--pretty=format:%H|%an|%ae|%ad|%s', 
                  '--date=iso']
        
        if since:
            command.extend(['--since', since])
        
        output = self._run_git_command(command)
        if not output:
            return {
                'commits': [],
                'direct_files': set(),
                'related_files': set(),
                'file_changes': {},
                'summary': {
                    'total_commits': 0,
                    'total_files': 0,
                    'total_additions': 0,
                    'total_deletions': 0
                }
            }
        
        commits = []
        pattern_regex = re.compile(pattern, re.IGNORECASE)
        
        for line in output.split('\n'):
            if not line.strip():
                continue
                
            parts = line.split('|', 4)
            if len(parts) != 5:
                continue
                
            commit_hash, author, email, date_str, message = parts
            
            if pattern_regex.search(message):
                try:
                    commit_date = datetime.fromisoformat(date_str.replace(' ', 'T', 1))
                except ValueError:
                    commit_date = datetime.now()
                
                detailed_commit = self._get_commit_details(commit_hash)
                commits.append(detailed_commit)
        
        if not commits:
            return {
                'commits': [],
                'direct_files': set(),
                'related_files': set(),
                'file_changes': {},
                'summary': {
                    'total_commits': 0,
                    'total_files': 0,
                    'total_additions': 0,
                    'total_deletions': 0
                }
            }
        
        # è·å–ç›´æ¥ä¿®æ”¹çš„æ–‡ä»¶
        direct_files = set()
        total_additions = total_deletions = 0
        
        for commit in commits:
            direct_files.update(commit.files_changed)
            total_additions += commit.additions
            total_deletions += commit.deletions
        
        # è·å–æ–‡ä»¶å˜æ›´è¯¦æƒ…
        file_changes = self.get_file_changes_by_commits(commits)
        
        # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
        related_files = set(direct_files)
        if include_dependencies:
            related_files.update(self._find_dependency_files(direct_files))
        
        return {
            'commits': commits,
            'direct_files': direct_files,
            'related_files': related_files,
            'file_changes': file_changes,
            'summary': {
                'total_commits': len(commits),
                'total_files': len(related_files),
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'time_range': {
                    'start': min(c.date for c in commits) if commits else None,
                    'end': max(c.date for c in commits) if commits else None
                }
            }
        }

    def _find_dependency_files(self, files: Set[str]) -> Set[str]:
        """
        æŸ¥æ‰¾ä¾èµ–æ–‡ä»¶ (ç®€å•å®ç°ï¼Œå¯æ ¹æ®é¡¹ç›®ç±»å‹æ‰©å±•)
        
        Args:
            files: ç›´æ¥ä¿®æ”¹çš„æ–‡ä»¶é›†åˆ
            
        Returns:
            ä¾èµ–æ–‡ä»¶é›†åˆ
        """
        dependencies = set()
        
        for file_path in files:
            if not os.path.exists(os.path.join(self.repo_path, file_path)):
                continue
                
            # æ ¹æ®æ–‡ä»¶ç±»å‹æŸ¥æ‰¾ä¾èµ–
            if file_path.endswith('.py'):
                dependencies.update(self._find_python_dependencies(file_path))
            elif file_path.endswith(('.js', '.ts')):
                dependencies.update(self._find_js_dependencies(file_path))
            elif file_path.endswith(('.java')):
                dependencies.update(self._find_java_dependencies(file_path))
        
        return dependencies
    
    def _find_python_dependencies(self, file_path: str) -> Set[str]:
        """æŸ¥æ‰¾Pythonæ–‡ä»¶çš„ä¾èµ–"""
        dependencies = set()
        full_path = os.path.join(self.repo_path, file_path)
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾importè¯­å¥
            import_pattern = r'from\s+(\S+)\s+import|import\s+(\S+)'
            matches = re.findall(import_pattern, content)
            
            for match in matches:
                module = match[0] or match[1]
                if module and not module.startswith('.'):
                    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„æœ¬åœ°æ–‡ä»¶
                    possible_paths = [
                        f"{module.replace('.', '/')}.py",
                        f"{module.replace('.', '/')}/__init__.py"
                    ]
                    
                    for possible_path in possible_paths:
                        if os.path.exists(os.path.join(self.repo_path, possible_path)):
                            dependencies.add(possible_path)
            
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†ææ–‡ä»¶ {file_path} çš„ä¾èµ–: {e}")
        
        return dependencies
    
    def _find_js_dependencies(self, file_path: str) -> Set[str]:
        """æŸ¥æ‰¾JavaScript/TypeScriptæ–‡ä»¶çš„ä¾èµ–"""
        dependencies = set()
        full_path = os.path.join(self.repo_path, file_path)
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾import/requireè¯­å¥
            import_patterns = [
                r'import.*from\s+[\'"]([^\'"]+)[\'"]',
                r'require\s*\(\s*[\'"]([^\'"]+)[\'"]\s*\)'
            ]
            
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if match.startswith('.'):
                        # ç›¸å¯¹è·¯å¾„å¯¼å…¥
                        base_dir = os.path.dirname(file_path)
                        resolved_path = os.path.normpath(
                            os.path.join(base_dir, match)
                        )
                        
                        # å°è¯•ä¸åŒçš„æ‰©å±•å
                        for ext in ['.js', '.ts', '.jsx', '.tsx']:
                            test_path = f"{resolved_path}{ext}"
                            if os.path.exists(os.path.join(self.repo_path, test_path)):
                                dependencies.add(test_path)
                                break
        
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†ææ–‡ä»¶ {file_path} çš„ä¾èµ–: {e}")
        
        return dependencies
    
    def _find_java_dependencies(self, file_path: str) -> Set[str]:
        """æŸ¥æ‰¾Javaæ–‡ä»¶çš„ä¾èµ–"""
        dependencies = set()
        full_path = os.path.join(self.repo_path, file_path)
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾importè¯­å¥
            import_pattern = r'import\s+([a-zA-Z_][a-zA-Z0-9_.]*);'
            matches = re.findall(import_pattern, content)
            
            for match in matches:
                # è½¬æ¢åŒ…åä¸ºæ–‡ä»¶è·¯å¾„
                path_parts = match.split('.')
                possible_path = '/'.join(path_parts) + '.java'
                
                if os.path.exists(os.path.join(self.repo_path, possible_path)):
                    dependencies.add(possible_path)
        
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†ææ–‡ä»¶ {file_path} çš„ä¾èµ–: {e}")
        
        return dependencies


class RequirementAnalyzer:
    """éœ€æ±‚åˆ†æå™¨ - åŸºäºå‰ç¼€åŒ¹é…"""
    
    def __init__(self, repo_path: str):
        self.git_analyzer = GitAnalyzer(repo_path)
    
    def analyze_requirement_by_prefix(self, prefix: str, 
                                    since: Optional[str] = '1 month ago') -> Dict[str, Any]:
        """
        é€šè¿‡æäº¤å‰ç¼€åˆ†æç‰¹å®šéœ€æ±‚çš„ä»£ç å˜æ›´
        
        Args:
            prefix: æäº¤æ¶ˆæ¯å‰ç¼€ (å¦‚: 'feat:', 'JIRA-123:', 'fix:')
            since: æ—¶é—´èŒƒå›´
            
        Returns:
            éœ€æ±‚åˆ†æç»“æœ
        """
        result = self.git_analyzer.get_files_by_commit_prefix(prefix, since=since)
        
        return {
            'prefix': prefix,
            'commits': result['commits'],
            'files': result['related_files'],
            'direct_files': result['direct_files'],
            'file_changes': result['file_changes'],
            'summary': result['summary']
        }
    
    def analyze_multiple_prefixes(self, prefixes: List[str],
                                since: Optional[str] = '1 month ago') -> Dict[str, Any]:
        """
        åˆ†æå¤šä¸ªå‰ç¼€çš„ä»£ç å˜æ›´ (ä¼˜åŒ–ç‰ˆæœ¬)
        
        Args:
            prefixes: å‰ç¼€åˆ—è¡¨
            since: æ—¶é—´èŒƒå›´
            
        Returns:
            åˆå¹¶çš„åˆ†æç»“æœ
        """
        # ä½¿ç”¨ä¼˜åŒ–åçš„å¤šå‰ç¼€æŸ¥è¯¢
        prefix_commits = self.git_analyzer.get_commits_by_multiple_prefixes_fast(
            prefixes, since=since
        )
        
        all_commits = []
        all_files = set()
        all_direct_files = set()
        prefix_results = {}
        
        for prefix, commits in prefix_commits.items():
            if commits:
                # è®¡ç®—æ–‡ä»¶ä¿¡æ¯
                direct_files = set()
                total_additions = total_deletions = 0
                
                for commit in commits:
                    direct_files.update(commit.files_changed)
                    total_additions += commit.additions
                    total_deletions += commit.deletions
                
                # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶ï¼ˆåŒ…å«ä¾èµ–ï¼‰
                related_files = set(direct_files)
                related_files.update(self.git_analyzer._find_dependency_files(direct_files))
                
                prefix_results[prefix] = {
                    'prefix': prefix,
                    'commits': commits,
                    'files': related_files,
                    'direct_files': direct_files,
                    'summary': {
                        'total_commits': len(commits),
                        'total_files': len(related_files),
                        'total_additions': total_additions,
                        'total_deletions': total_deletions,
                        'time_range': {
                            'start': min(c.date for c in commits) if commits else None,
                            'end': max(c.date for c in commits) if commits else None
                        }
                    }
                }
                
                all_commits.extend(commits)
                all_files.update(related_files)
                all_direct_files.update(direct_files)
        
        # å»é‡æäº¤è®°å½•
        unique_commits = {}
        for commit in all_commits:
            unique_commits[commit.hash] = commit
        unique_commits_list = list(unique_commits.values())
        
        return {
            'prefixes': prefixes,
            'prefix_results': prefix_results,
            'combined_commits': unique_commits_list,
            'combined_files': all_files,
            'combined_direct_files': all_direct_files,
            'summary': {
                'total_commits': len(unique_commits_list),
                'total_files': len(all_files),
                'total_direct_files': len(all_direct_files),
                'total_additions': sum(c.additions for c in unique_commits_list),
                'total_deletions': sum(c.deletions for c in unique_commits_list),
                'date_range': {
                    'start': min(c.date for c in unique_commits_list) if unique_commits_list else None,
                    'end': max(c.date for c in unique_commits_list) if unique_commits_list else None
                }
            }
        }
    
    def analyze_requirement(self, requirement_id: str, 
                          patterns: Optional[List[str]] = None,
                          since: Optional[str] = '1 month ago') -> Dict[str, Any]:
        """
        åˆ†æç‰¹å®šéœ€æ±‚çš„ä»£ç å˜æ›´ (ä¿ç•™å‘åå…¼å®¹æ€§)
        
        Args:
            requirement_id: éœ€æ±‚ID
            patterns: é¢å¤–çš„æœç´¢æ¨¡å¼
            since: æ—¶é—´èŒƒå›´
            
        Returns:
            éœ€æ±‚åˆ†æç»“æœ
        """
        # ä¼˜å…ˆä½¿ç”¨å‰ç¼€åŒ¹é…
        if patterns is None:
            patterns = []
        
        # æ„å»ºå‰ç¼€åˆ—è¡¨
        prefixes = [
            f"{requirement_id}:",
            f"feat({requirement_id}):",
            f"fix({requirement_id}):",
            f"feat: {requirement_id}",
            f"fix: {requirement_id}",
        ] + patterns
        
        return self.analyze_multiple_prefixes(prefixes, since)
    
    def export_analysis_report(self, analysis_result: Dict[str, Any], 
                             output_file: str = None) -> str:
        """
        å¯¼å‡ºåˆ†ææŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        report_lines = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append(f"# éœ€æ±‚ä»£ç åˆ†ææŠ¥å‘Š")
        report_lines.append(f"**éœ€æ±‚ID**: {analysis_result['requirement_id']}")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        summary = analysis_result['overall_summary']
        report_lines.append("## æ€»ä½“ç»Ÿè®¡")
        report_lines.append(f"- ç›¸å…³æäº¤æ•°: {summary['total_commits']}")
        report_lines.append(f"- å½±å“æ–‡ä»¶æ•°: {summary['total_files']}")
        report_lines.append(f"- ä»£ç æ–°å¢è¡Œæ•°: {summary['total_additions']}")
        report_lines.append(f"- ä»£ç åˆ é™¤è¡Œæ•°: {summary['total_deletions']}")
        
        if summary['date_range']['start']:
            start_date = summary['date_range']['start'].strftime('%Y-%m-%d')
            end_date = summary['date_range']['end'].strftime('%Y-%m-%d')
            report_lines.append(f"- æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
        
        report_lines.append("")
        
        # ç›¸å…³æ–‡ä»¶åˆ—è¡¨
        report_lines.append("## ç›¸å…³æ–‡ä»¶åˆ—è¡¨")
        for file_path in sorted(analysis_result['files']):
            report_lines.append(f"- {file_path}")
        report_lines.append("")
        
        # æäº¤è¯¦æƒ…
        report_lines.append("## æäº¤è¯¦æƒ…")
        for commit in sorted(analysis_result['commits'], key=lambda x: x.date, reverse=True):
            report_lines.append(f"### {commit.hash[:8]} - {commit.message}")
            report_lines.append(f"- **ä½œè€…**: {commit.author} ({commit.email})")
            report_lines.append(f"- **æ—¶é—´**: {commit.date.strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append(f"- **å˜æ›´**: +{commit.additions}/-{commit.deletions}")
            report_lines.append(f"- **æ–‡ä»¶**: {', '.join(commit.files_changed)}")
            report_lines.append("")
        
        report_content = '\n'.join(report_lines)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
        
        return report_content


# ä¾¿æ·å‡½æ•°
def analyze_requirement_changes(repo_path: str, requirement_id: str, 
                              since: str = '1 month ago') -> Dict[str, Any]:
    """
    åˆ†æéœ€æ±‚ç›¸å…³çš„ä»£ç å˜æ›´çš„ä¾¿æ·å‡½æ•°
    
    Args:
        repo_path: Gitä»“åº“è·¯å¾„
        requirement_id: éœ€æ±‚ID
        since: æ—¶é—´èŒƒå›´
        
    Returns:
        åˆ†æç»“æœ
    """
    analyzer = RequirementAnalyzer(repo_path)
    return analyzer.analyze_requirement_by_prefix(f"{requirement_id}:", since=since)


def analyze_by_commit_prefix(repo_path: str, prefix: str, 
                           since: str = '1 month ago') -> Dict[str, Any]:
    """
    é€šè¿‡æäº¤å‰ç¼€åˆ†æä»£ç å˜æ›´çš„ä¾¿æ·å‡½æ•°
    
    Args:
        repo_path: Gitä»“åº“è·¯å¾„
        prefix: æäº¤æ¶ˆæ¯å‰ç¼€ (å¦‚: 'feat:', 'fix:', 'JIRA-123:')
        since: æ—¶é—´èŒƒå›´
        
    Returns:
        åˆ†æç»“æœ
    """
    analyzer = RequirementAnalyzer(repo_path)
    return analyzer.analyze_requirement_by_prefix(prefix, since=since)


def get_files_for_review_by_prefix(repo_path: str, prefix: str) -> List[str]:
    """
    é€šè¿‡å‰ç¼€è·å–éœ€è¦ä»£ç å®¡æŸ¥çš„æ–‡ä»¶åˆ—è¡¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        repo_path: Gitä»“åº“è·¯å¾„
        prefix: æäº¤æ¶ˆæ¯å‰ç¼€
        
    Returns:
        éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    git_analyzer = GitAnalyzer(repo_path)
    result = git_analyzer.get_files_by_commit_prefix(prefix)
    return list(result['related_files'])


def get_files_for_review(repo_path: str, requirement_pattern: str) -> List[str]:
    """
    è·å–éœ€è¦ä»£ç å®¡æŸ¥çš„æ–‡ä»¶åˆ—è¡¨çš„ä¾¿æ·å‡½æ•° (ä¿ç•™å‘åå…¼å®¹æ€§)
    
    Args:
        repo_path: Gitä»“åº“è·¯å¾„
        requirement_pattern: éœ€æ±‚åŒ¹é…æ¨¡å¼
        
    Returns:
        éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    git_analyzer = GitAnalyzer(repo_path)
    result = git_analyzer.get_related_files_by_requirement(requirement_pattern)
    return list(result['related_files'])


if __name__ == "__main__":
    # å®Œæ•´åŠŸèƒ½æµ‹è¯•
    repo_path = r"D:\Projects\MofficeProjects\moffice_dialog_mgr"
    
    try:
        print("=== Gitå¤„ç†æ¨¡å—åŠŸèƒ½æµ‹è¯• ===")
        
        # 1. åˆå§‹åŒ–åˆ†æå™¨
        print("\n1. åˆå§‹åŒ–åˆ†æå™¨...")
        analyzer = GitAnalyzer(repo_path)
        req_analyzer = RequirementAnalyzer(repo_path)
        print("âœ… åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. æµ‹è¯•åŸºæœ¬Gitæ“ä½œ
        print("\n2. æµ‹è¯•åŸºæœ¬Gitæ“ä½œ...")
        recent_commits = analyzer._run_git_command(['log', '--oneline', '-3'])
        print("âœ… Gitå‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
        print(f"æœ€è¿‘3ä¸ªæäº¤:")
        for line in recent_commits.split('\n')[:3]:
            if line.strip():
                print(f"  - {line[:60]}...")
        
        # # 3. æµ‹è¯•å‰ç¼€åŒ¹é…åŠŸèƒ½
        # print("\n3. æµ‹è¯•å‰ç¼€åŒ¹é…åŠŸèƒ½...")
        # test_prefix = "éœ€æ±‚æè¿°ï¼šWPSé¸¿è’™ç‰ˆï¼ˆOHï¼‰å¼¹çª—ç®¡ç†å¼€å‘"
        # commits = analyzer.get_commits_by_prefix(test_prefix)
        # print(f"âœ… å‰ç¼€åŒ¹é…æˆåŠŸï¼Œæ‰¾åˆ° {len(commits)} ä¸ªç›¸å…³æäº¤")
        
        # for i, commit in enumerate(commits[:2]):
        #     print(f"  æäº¤ {i+1}: {commit.hash[:8]} - {commit.message[:50]}...")
        #     print(f"    ä½œè€…: {commit.author}")
        #     print(f"    å˜æ›´: +{commit.additions}/-{commit.deletions}")
        #     print(f"    æ–‡ä»¶æ•°: {len(commit.files_changed)}")
        
        # # 4. æµ‹è¯•æ–‡ä»¶åˆ†æåŠŸèƒ½
        # print("\n4. æµ‹è¯•æ–‡ä»¶åˆ†æåŠŸèƒ½...")
        # file_result = analyzer.get_files_by_commit_prefix(test_prefix)
        # print(f"âœ… æ–‡ä»¶åˆ†ææˆåŠŸ")
        # print(f"  - ç›¸å…³æäº¤æ•°: {file_result['summary']['total_commits']}")
        # print(f"  - ç›´æ¥å½±å“æ–‡ä»¶: {len(file_result['direct_files'])}")
        # print(f"  - åŒ…å«ä¾èµ–æ–‡ä»¶: {len(file_result['related_files'])}")
        # print(f"  - ä»£ç å˜æ›´: +{file_result['summary']['total_additions']}/-{file_result['summary']['total_deletions']}")
        
        # if file_result['direct_files']:
        #     print("  ä¸»è¦å½±å“çš„æ–‡ä»¶:")
        #     for file_path in sorted(list(file_result['direct_files'])[:5]):
        #         print(f"    - {file_path}")
        
        # # 5. æµ‹è¯•éœ€æ±‚åˆ†æåŠŸèƒ½
        # print("\n5. æµ‹è¯•éœ€æ±‚åˆ†æåŠŸèƒ½...")
        # requirement_result = req_analyzer.analyze_requirement_by_prefix(test_prefix)
        # print(f"âœ… éœ€æ±‚åˆ†ææˆåŠŸ")
        # print(f"  - éœ€æ±‚å‰ç¼€: {requirement_result['prefix']}")
        # print(f"  - ç›¸å…³æäº¤: {len(requirement_result['commits'])}")
        # print(f"  - æ¶‰åŠæ–‡ä»¶: {len(requirement_result['files'])}")
        
        # # 6. æµ‹è¯•ä¾¿æ·å‡½æ•°
        # print("\n6. æµ‹è¯•ä¾¿æ·å‡½æ•°...")
        # files_for_review = get_files_for_review_by_prefix(repo_path, test_prefix)
        # print(f"âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•æˆåŠŸ")
        # print(f"  éœ€è¦ä»£ç å®¡æŸ¥çš„æ–‡ä»¶æ•°: {len(files_for_review)}")
        
        # 7. æµ‹è¯•å¤šå‰ç¼€åŒ¹é…
        print("\n7. æµ‹è¯•å¤šå‰ç¼€åŒ¹é…...")
        multiple_prefixes = [
            "éœ€æ±‚æè¿°ï¼šWPSé¸¿è’™ç‰ˆï¼ˆOHï¼‰å¼¹çª—ç®¡ç†å¼€å‘",
            "éœ€æ±‚æè¿°ï¼šWPSé¸¿è’™ç‰ˆï¼ˆOHï¼‰å¥½è¯„å¼¹çª—",
            "éœ€æ±‚æè¿°ï¼šWPSé¸¿è’™ å°é²œç‰ˆå¼¹çª—æ§åˆ¶",
        ]
        multi_result = req_analyzer.analyze_multiple_prefixes(multiple_prefixes)
        print(f"âœ… å¤šå‰ç¼€åŒ¹é…æˆåŠŸ")
        print(f"  - æµ‹è¯•å‰ç¼€æ•°: {len(multiple_prefixes)}")
        print(f"  - åˆå¹¶åæäº¤æ•°: {len(multi_result['combined_commits'])}")
        print(f"  - åˆå¹¶åæ–‡ä»¶æ•°: {len(multi_result['combined_files'])}")
        
        # 8. æ€»ç»“
        print("\n=== åŠŸèƒ½æµ‹è¯•æ€»ç»“ ===")
        print("âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        print("ä¸»è¦åŠŸèƒ½:")
        print("  âœ“ Gitä»“åº“éªŒè¯å’ŒåŸºæœ¬æ“ä½œ")
        print("  âœ“ å‰ç¼€åŒ¹é…ç®—æ³• (æ”¯æŒä»»æ„é•¿åº¦)")
        print("  âœ“ æäº¤è¯¦æƒ…è·å–å’Œè§£æ")
        print("  âœ“ æ–‡ä»¶å˜æ›´åˆ†æ")
        print("  âœ“ ä¾èµ–æ–‡ä»¶å‘ç°")
        print("  âœ“ éœ€æ±‚åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ")
        print("  âœ“ å¤šå‰ç¼€åˆå¹¶åˆ†æ")
        print("  âœ“ ä¾¿æ·å‡½æ•°æ¥å£")
        
        print(f"\næ¨¡å—çŠ¶æ€: ğŸŸ¢ å°±ç»ªï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        print(f"\næ¨¡å—çŠ¶æ€: ğŸ”´ éœ€è¦ä¿®å¤")
